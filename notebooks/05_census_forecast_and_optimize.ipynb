{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05 — Census Forecasting + Staffing Auto-Optimizer\n",
        "\n",
        "This notebook:\n",
        "1. Generates historical census patterns (synthetic but realistic)\n",
        "2. Trains a lightweight ML model to predict next-day census per unit\n",
        "3. Runs a staffing optimizer to recommend optimal nurse mix\n",
        "4. Outputs predictions and recommendations to gold tables\n",
        "\n",
        "**Serverless-compatible**: Uses pandas/sklearn instead of Spark ML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip install scikit-learn==1.4.2 pandas numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dbutils.library.restartPython()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Parameters (set by DAB or widget defaults)\n",
        "dbutils.widgets.text(\"catalog\", \"rtpa_catalog\")\n",
        "dbutils.widgets.text(\"schema_ref\", \"credentialing_ref\")\n",
        "dbutils.widgets.text(\"schema_gold\", \"credentialing_gold\")\n",
        "dbutils.widgets.text(\"seed\", \"42\")\n",
        "\n",
        "catalog = dbutils.widgets.get(\"catalog\")\n",
        "schema_ref = dbutils.widgets.get(\"schema_ref\")\n",
        "schema_gold = dbutils.widgets.get(\"schema_gold\")\n",
        "seed = int(dbutils.widgets.get(\"seed\"))\n",
        "\n",
        "print(f\"Catalog: {catalog}, Gold Schema: {schema_gold}, Seed: {seed}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate Historical Census Data\n",
        "\n",
        "Creates 90 days of realistic census patterns per unit with:\n",
        "- Day-of-week seasonality (weekends lower)\n",
        "- Unit-type patterns (ICU more stable, ED more volatile)\n",
        "- Random noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Load units from reference table with facility name\n",
        "units_df = spark.sql(f\"\"\"\n",
        "    SELECT u.unit_id, u.unit_name, u.unit_type, u.facility_id, u.bed_count, u.target_ratio,\n",
        "           COALESCE(f.facility_name, u.facility_id) as facility_name\n",
        "    FROM {catalog}.{schema_ref}.unit u\n",
        "    LEFT JOIN {catalog}.{schema_ref}.facility f ON u.facility_id = f.facility_id\n",
        "\"\"\").toPandas()\n",
        "print(f\"Loaded {len(units_df)} units\")\n",
        "display(units_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate 90 days of historical census data\n",
        "HISTORY_DAYS = 90\n",
        "today = datetime.now().date()\n",
        "dates = [today - timedelta(days=i) for i in range(HISTORY_DAYS, 0, -1)]\n",
        "\n",
        "# Unit-type volatility (how much census fluctuates)\n",
        "VOLATILITY = {\n",
        "    \"ICU\": 0.10, \"NICU\": 0.12, \"STEP_DOWN\": 0.15,\n",
        "    \"MED_SURG\": 0.20, \"TELEMETRY\": 0.18,\n",
        "    \"ED\": 0.30, \"OR\": 0.25, \"PACU\": 0.20,\n",
        "    \"L_AND_D\": 0.35, \"PSYCH\": 0.15\n",
        "}\n",
        "\n",
        "# Day-of-week multipliers (0=Mon, 6=Sun)\n",
        "DOW_MULT = {0: 1.0, 1: 1.02, 2: 1.05, 3: 1.03, 4: 0.98, 5: 0.85, 6: 0.80}\n",
        "\n",
        "census_records = []\n",
        "for _, unit in units_df.iterrows():\n",
        "    unit_id = unit[\"unit_id\"]\n",
        "    bed_count = unit[\"bed_count\"]\n",
        "    unit_type = unit[\"unit_type\"]\n",
        "    target_ratio = unit[\"target_ratio\"]\n",
        "    \n",
        "    # Base occupancy (ICU higher, MED_SURG lower)\n",
        "    base_occupancy = {\"ICU\": 0.85, \"NICU\": 0.80, \"ED\": 0.75, \"MED_SURG\": 0.70}.get(unit_type, 0.75)\n",
        "    volatility = VOLATILITY.get(unit_type, 0.20)\n",
        "    \n",
        "    for dt in dates:\n",
        "        dow = dt.weekday()\n",
        "        dow_mult = DOW_MULT[dow]\n",
        "        \n",
        "        # Add trend (slight increase over time to simulate growth)\n",
        "        day_idx = (dt - dates[0]).days\n",
        "        trend = 1.0 + (day_idx / HISTORY_DAYS) * 0.05\n",
        "        \n",
        "        # Calculate census with noise\n",
        "        noise = np.random.normal(0, volatility)\n",
        "        occupancy = base_occupancy * dow_mult * trend * (1 + noise)\n",
        "        census = int(np.clip(occupancy * bed_count, 1, bed_count))\n",
        "        \n",
        "        # Calculate required nurses based on ratio\n",
        "        nurses_required = max(1, int(np.ceil(census / target_ratio)))\n",
        "        \n",
        "        census_records.append({\n",
        "            \"census_date\": dt,\n",
        "            \"unit_id\": unit_id,\n",
        "            \"facility_id\": unit[\"facility_id\"],\n",
        "            \"unit_type\": unit_type,\n",
        "            \"bed_count\": bed_count,\n",
        "            \"target_ratio\": target_ratio,\n",
        "            \"census\": census,\n",
        "            \"occupancy_pct\": round(census / bed_count * 100, 1),\n",
        "            \"nurses_required\": nurses_required,\n",
        "            \"day_of_week\": dow,\n",
        "            \"is_weekend\": dow >= 5\n",
        "        })\n",
        "\n",
        "census_history = pd.DataFrame(census_records)\n",
        "print(f\"Generated {len(census_history)} census records\")\n",
        "display(census_history.head(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save historical census to gold table\n",
        "spark.createDataFrame(census_history).write.mode(\"overwrite\").saveAsTable(\n",
        "    f\"{catalog}.{schema_gold}.census_history\"\n",
        ")\n",
        "print(f\"Wrote census_history to {catalog}.{schema_gold}.census_history\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train Census Forecasting Model\n",
        "\n",
        "Uses a simple Random Forest to predict next-day census based on:\n",
        "- Unit characteristics (type, bed count)\n",
        "- Recent census trends (lag features)\n",
        "- Day of week"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create lag features (census from previous days)\n",
        "def create_features(df):\n",
        "    df = df.sort_values([\"unit_id\", \"census_date\"]).copy()\n",
        "    \n",
        "    # Lag features per unit\n",
        "    for lag in [1, 2, 3, 7]:  # yesterday, 2 days ago, 3 days ago, same day last week\n",
        "        df[f\"census_lag_{lag}\"] = df.groupby(\"unit_id\")[\"census\"].shift(lag)\n",
        "    \n",
        "    # Rolling averages\n",
        "    df[\"census_rolling_3d\"] = df.groupby(\"unit_id\")[\"census\"].transform(\n",
        "        lambda x: x.rolling(3, min_periods=1).mean()\n",
        "    )\n",
        "    df[\"census_rolling_7d\"] = df.groupby(\"unit_id\")[\"census\"].transform(\n",
        "        lambda x: x.rolling(7, min_periods=1).mean()\n",
        "    )\n",
        "    \n",
        "    return df.dropna()\n",
        "\n",
        "# Prepare features\n",
        "df_features = create_features(census_history)\n",
        "print(f\"Training samples after feature engineering: {len(df_features)}\")\n",
        "\n",
        "# Encode categorical variables\n",
        "le_unit_type = LabelEncoder()\n",
        "le_unit = LabelEncoder()\n",
        "df_features[\"unit_type_enc\"] = le_unit_type.fit_transform(df_features[\"unit_type\"])\n",
        "df_features[\"unit_id_enc\"] = le_unit.fit_transform(df_features[\"unit_id\"])\n",
        "\n",
        "# Feature columns\n",
        "feature_cols = [\n",
        "    \"unit_type_enc\", \"unit_id_enc\", \"bed_count\", \"target_ratio\",\n",
        "    \"day_of_week\", \"is_weekend\",\n",
        "    \"census_lag_1\", \"census_lag_2\", \"census_lag_3\", \"census_lag_7\",\n",
        "    \"census_rolling_3d\", \"census_rolling_7d\"\n",
        "]\n",
        "\n",
        "X = df_features[feature_cols]\n",
        "y = df_features[\"census\"]\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=seed, n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Model Performance:\")\n",
        "print(f\"  MAE: {mae:.2f} patients\")\n",
        "print(f\"  R²: {r2:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature importance\n",
        "importance = pd.DataFrame({\n",
        "    \"feature\": feature_cols,\n",
        "    \"importance\": model.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "display(importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate 7-Day Census Forecast\n",
        "\n",
        "Predicts census for the next 7 days per unit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate forecast for next 7 days\n",
        "FORECAST_DAYS = 7\n",
        "forecast_dates = [today + timedelta(days=i) for i in range(1, FORECAST_DAYS + 1)]\n",
        "\n",
        "forecasts = []\n",
        "for _, unit in units_df.iterrows():\n",
        "    unit_id = unit[\"unit_id\"]\n",
        "    \n",
        "    # Get recent history for this unit\n",
        "    unit_history = census_history[census_history[\"unit_id\"] == unit_id].sort_values(\"census_date\")\n",
        "    recent = unit_history.tail(7)[\"census\"].tolist()\n",
        "    \n",
        "    for i, forecast_date in enumerate(forecast_dates):\n",
        "        dow = forecast_date.weekday()\n",
        "        \n",
        "        # Build features for prediction\n",
        "        features = {\n",
        "            \"unit_type_enc\": le_unit_type.transform([unit[\"unit_type\"]])[0],\n",
        "            \"unit_id_enc\": le_unit.transform([unit_id])[0],\n",
        "            \"bed_count\": unit[\"bed_count\"],\n",
        "            \"target_ratio\": unit[\"target_ratio\"],\n",
        "            \"day_of_week\": dow,\n",
        "            \"is_weekend\": dow >= 5,\n",
        "            \"census_lag_1\": recent[-1] if recent else unit[\"bed_count\"] * 0.7,\n",
        "            \"census_lag_2\": recent[-2] if len(recent) > 1 else unit[\"bed_count\"] * 0.7,\n",
        "            \"census_lag_3\": recent[-3] if len(recent) > 2 else unit[\"bed_count\"] * 0.7,\n",
        "            \"census_lag_7\": recent[-7] if len(recent) >= 7 else unit[\"bed_count\"] * 0.7,\n",
        "            \"census_rolling_3d\": np.mean(recent[-3:]) if recent else unit[\"bed_count\"] * 0.7,\n",
        "            \"census_rolling_7d\": np.mean(recent) if recent else unit[\"bed_count\"] * 0.7,\n",
        "        }\n",
        "        \n",
        "        # Predict\n",
        "        X_pred = pd.DataFrame([features])\n",
        "        predicted_census = int(np.clip(model.predict(X_pred)[0], 1, unit[\"bed_count\"]))\n",
        "        nurses_required = max(1, int(np.ceil(predicted_census / unit[\"target_ratio\"])))\n",
        "        \n",
        "        # Calculate confidence (based on historical volatility)\n",
        "        volatility = VOLATILITY.get(unit[\"unit_type\"], 0.20)\n",
        "        confidence = round(max(0.6, 1 - volatility) * 100)\n",
        "        \n",
        "        forecasts.append({\n",
        "            \"forecast_date\": forecast_date,\n",
        "            \"unit_id\": unit_id,\n",
        "            \"facility_id\": unit[\"facility_id\"],\n",
        "            \"facility_name\": unit[\"facility_name\"],\n",
        "            \"unit_name\": unit[\"unit_name\"],\n",
        "            \"unit_type\": unit[\"unit_type\"],\n",
        "            \"bed_count\": unit[\"bed_count\"],\n",
        "            \"predicted_census\": predicted_census,\n",
        "            \"predicted_occupancy_pct\": round(predicted_census / unit[\"bed_count\"] * 100, 1),\n",
        "            \"nurses_required\": nurses_required,\n",
        "            \"confidence_pct\": confidence,\n",
        "            \"day_of_week\": dow,\n",
        "            \"is_weekend\": dow >= 5,\n",
        "            \"generated_at\": datetime.now()\n",
        "        })\n",
        "        \n",
        "        # Update recent for next iteration (rolling forecast)\n",
        "        recent.append(predicted_census)\n",
        "        recent = recent[-7:]\n",
        "\n",
        "forecast_df = pd.DataFrame(forecasts)\n",
        "print(f\"Generated {len(forecast_df)} forecasts\")\n",
        "display(forecast_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save forecasts to gold table\n",
        "spark.createDataFrame(forecast_df).write.mode(\"overwrite\").saveAsTable(\n",
        "    f\"{catalog}.{schema_gold}.census_forecast\"\n",
        ")\n",
        "print(f\"Wrote forecasts to {catalog}.{schema_gold}.census_forecast\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Staffing Auto-Optimizer\n",
        "\n",
        "Generates optimal staffing recommendations that minimize cost while meeting demand.\n",
        "\n",
        "**Optimization logic:**\n",
        "- Prioritize internal staff (cheapest)\n",
        "- Use contract nurses for predictable gaps\n",
        "- Agency only for urgent/unexpected needs\n",
        "- Factor in credential requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hourly rates by employment type\n",
        "HOURLY_RATES = {\"INTERNAL\": 50, \"CONTRACT\": 75, \"AGENCY\": 95}\n",
        "SHIFT_HOURS = 12\n",
        "\n",
        "# Current staffing from nurse_staffing_summary\n",
        "try:\n",
        "    current_staffing = spark.sql(f\"\"\"\n",
        "        SELECT unit_id, nurses_internal, nurses_contract, nurses_agency, nurses_assigned\n",
        "        FROM {catalog}.{schema_gold}.nurse_staffing_summary\n",
        "        WHERE summary_date = (SELECT MAX(summary_date) FROM {catalog}.{schema_gold}.nurse_staffing_summary)\n",
        "    \"\"\").toPandas()\n",
        "    print(f\"Loaded current staffing for {len(current_staffing)} units\")\n",
        "except:\n",
        "    # Fallback if table doesn't exist\n",
        "    current_staffing = pd.DataFrame()\n",
        "    print(\"No current staffing data, using defaults\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def optimize_staffing(nurses_required, current_internal=0, current_contract=0, max_agency_pct=0.20):\n",
        "    \"\"\"\n",
        "    Optimize staffing mix to minimize cost while meeting demand.\n",
        "    \n",
        "    Strategy:\n",
        "    1. Use all available internal staff first\n",
        "    2. Fill predictable gaps with contract\n",
        "    3. Use agency only for remaining (up to max_agency_pct)\n",
        "    \"\"\"\n",
        "    # Start with internal (cheapest)\n",
        "    internal = min(current_internal, nurses_required)\n",
        "    remaining = nurses_required - internal\n",
        "    \n",
        "    # Then contract\n",
        "    contract = min(current_contract, remaining)\n",
        "    remaining -= contract\n",
        "    \n",
        "    # Agency for the rest (capped at max %)\n",
        "    max_agency = int(nurses_required * max_agency_pct)\n",
        "    agency = min(remaining, max_agency)\n",
        "    remaining -= agency\n",
        "    \n",
        "    # If still short, add more contract\n",
        "    if remaining > 0:\n",
        "        contract += remaining\n",
        "    \n",
        "    total = internal + contract + agency\n",
        "    cost = (internal * HOURLY_RATES[\"INTERNAL\"] + \n",
        "            contract * HOURLY_RATES[\"CONTRACT\"] + \n",
        "            agency * HOURLY_RATES[\"AGENCY\"]) * SHIFT_HOURS\n",
        "    \n",
        "    return {\n",
        "        \"opt_internal\": internal,\n",
        "        \"opt_contract\": contract,\n",
        "        \"opt_agency\": agency,\n",
        "        \"opt_total\": total,\n",
        "        \"opt_daily_cost\": cost,\n",
        "        \"internal_pct\": round(internal / total * 100, 1) if total > 0 else 0,\n",
        "        \"outsourced_pct\": round((contract + agency) / total * 100, 1) if total > 0 else 0\n",
        "    }\n",
        "\n",
        "# Generate optimization recommendations\n",
        "recommendations = []\n",
        "for _, forecast in forecast_df.iterrows():\n",
        "    unit_id = forecast[\"unit_id\"]\n",
        "    \n",
        "    # Get current staffing for this unit\n",
        "    if len(current_staffing) > 0 and unit_id in current_staffing[\"unit_id\"].values:\n",
        "        curr = current_staffing[current_staffing[\"unit_id\"] == unit_id].iloc[0]\n",
        "        current_internal = curr[\"nurses_internal\"]\n",
        "        current_contract = curr[\"nurses_contract\"]\n",
        "        current_total = curr[\"nurses_assigned\"]\n",
        "    else:\n",
        "        # Default assumption: 60% internal capacity available\n",
        "        current_internal = int(forecast[\"nurses_required\"] * 0.6)\n",
        "        current_contract = int(forecast[\"nurses_required\"] * 0.2)\n",
        "        current_total = 0\n",
        "    \n",
        "    # Run optimizer\n",
        "    opt = optimize_staffing(\n",
        "        nurses_required=forecast[\"nurses_required\"],\n",
        "        current_internal=current_internal,\n",
        "        current_contract=current_contract\n",
        "    )\n",
        "    \n",
        "    # Calculate current cost for comparison\n",
        "    if current_total > 0:\n",
        "        current_cost = (\n",
        "            curr.get(\"nurses_internal\", 0) * HOURLY_RATES[\"INTERNAL\"] +\n",
        "            curr.get(\"nurses_contract\", 0) * HOURLY_RATES[\"CONTRACT\"] +\n",
        "            curr.get(\"nurses_agency\", 0) * HOURLY_RATES[\"AGENCY\"]\n",
        "        ) * SHIFT_HOURS\n",
        "    else:\n",
        "        current_cost = opt[\"opt_daily_cost\"]\n",
        "    \n",
        "    # Determine recommendation action\n",
        "    delta = forecast[\"nurses_required\"] - current_total if current_total > 0 else 0\n",
        "    if delta > 0:\n",
        "        action = f\"STAFF_UP: Add {delta} nurse(s)\"\n",
        "        priority = \"HIGH\" if delta >= 2 else \"MEDIUM\"\n",
        "    elif delta < 0:\n",
        "        action = f\"OPTIMIZE: Reduce {-delta} nurse(s)\"\n",
        "        priority = \"LOW\"\n",
        "    else:\n",
        "        action = \"OPTIMAL: Staffing matches demand\"\n",
        "        priority = \"LOW\"\n",
        "    \n",
        "    recommendations.append({\n",
        "        \"forecast_date\": forecast[\"forecast_date\"],\n",
        "        \"unit_id\": unit_id,\n",
        "        \"facility_id\": forecast[\"facility_id\"],\n",
        "        \"facility_name\": forecast[\"facility_name\"],\n",
        "        \"unit_name\": forecast[\"unit_name\"],\n",
        "        \"unit_type\": forecast[\"unit_type\"],\n",
        "        \"predicted_census\": forecast[\"predicted_census\"],\n",
        "        \"nurses_required\": forecast[\"nurses_required\"],\n",
        "        \"current_staffed\": current_total,\n",
        "        \"staffing_delta\": delta,\n",
        "        **opt,\n",
        "        \"current_daily_cost\": current_cost,\n",
        "        \"cost_savings\": current_cost - opt[\"opt_daily_cost\"],\n",
        "        \"action\": action,\n",
        "        \"priority\": priority,\n",
        "        \"confidence_pct\": forecast[\"confidence_pct\"],\n",
        "        \"generated_at\": datetime.now()\n",
        "    })\n",
        "\n",
        "recommendations_df = pd.DataFrame(recommendations)\n",
        "print(f\"Generated {len(recommendations_df)} staffing recommendations\")\n",
        "display(recommendations_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save recommendations to gold table\n",
        "spark.createDataFrame(recommendations_df).write.mode(\"overwrite\").saveAsTable(\n",
        "    f\"{catalog}.{schema_gold}.staffing_optimization\"\n",
        ")\n",
        "print(f\"Wrote recommendations to {catalog}.{schema_gold}.staffing_optimization\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary: 7-Day Outlook\n",
        "\n",
        "Aggregate view of predicted demand and optimization opportunities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Daily summary\n",
        "daily_summary = recommendations_df.groupby(\"forecast_date\").agg({\n",
        "    \"nurses_required\": \"sum\",\n",
        "    \"opt_total\": \"sum\",\n",
        "    \"opt_daily_cost\": \"sum\",\n",
        "    \"cost_savings\": \"sum\"\n",
        "}).reset_index()\n",
        "daily_summary.columns = [\"date\", \"total_nurses_needed\", \"optimized_nurses\", \"optimized_cost\", \"potential_savings\"]\n",
        "\n",
        "print(\"7-Day Staffing Outlook:\")\n",
        "display(daily_summary)\n",
        "\n",
        "total_savings = daily_summary[\"potential_savings\"].sum()\n",
        "print(f\"\\nTotal 7-day potential savings: ${total_savings:,.0f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Units needing attention (high priority recommendations)\n",
        "high_priority = recommendations_df[\n",
        "    (recommendations_df[\"priority\"] == \"HIGH\") & \n",
        "    (recommendations_df[\"forecast_date\"] == forecast_dates[0])\n",
        "][[\"unit_name\", \"facility_name\", \"predicted_census\", \"nurses_required\", \"current_staffed\", \"staffing_delta\", \"action\"]]\n",
        "\n",
        "print(f\"\\nHigh-priority units for tomorrow ({forecast_dates[0]}):\")\n",
        "if len(high_priority) > 0:\n",
        "    display(high_priority)\n",
        "else:\n",
        "    print(\"All units optimally staffed!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CENSUS FORECASTING + AUTO-OPTIMIZER COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTables created/updated:\")\n",
        "print(f\"  - {catalog}.{schema_gold}.census_history\")\n",
        "print(f\"  - {catalog}.{schema_gold}.census_forecast\")\n",
        "print(f\"  - {catalog}.{schema_gold}.staffing_optimization\")\n",
        "print(f\"\\nModel metrics:\")\n",
        "print(f\"  - MAE: {mae:.2f} patients\")\n",
        "print(f\"  - R²: {r2:.3f}\")\n",
        "print(f\"\\n7-day outlook:\")\n",
        "print(f\"  - Total nurses needed: {daily_summary['total_nurses_needed'].sum()}\")\n",
        "print(f\"  - Potential cost savings: ${total_savings:,.0f}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "def77ed7",
      "metadata": {},
      "source": [
        "# 01 â€” Seed reference data (Unity Catalog + Delta) [web:9][web:15]\n",
        "\n",
        "Creates small reference tables under the `ref` schema used by subsequent notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e74887ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install faker==25.2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf679320",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration (Databricks widgets)\n",
        "# These widgets make the demo portable across workspaces/accounts.\n",
        "# If you're running this outside a Databricks notebook, it will fall back to defaults.\n",
        "\n",
        "DEFAULT_CATALOG = \"rtpa_catalog\"\n",
        "DEFAULT_SCHEMA_REF = \"credentialing_ref\"\n",
        "DEFAULT_SCHEMA_BRONZE = \"credentialing_bronze\"\n",
        "DEFAULT_SCHEMA_SILVER = \"credentialing_silver\"\n",
        "DEFAULT_SCHEMA_GOLD = \"credentialing_gold\"\n",
        "\n",
        "DEFAULT_N_PROVIDERS = 200\n",
        "DEFAULT_DAYS_SCHEDULE = 14\n",
        "DEFAULT_SEED = 42\n",
        "\n",
        "try:\n",
        "    dbutils.widgets.text(\"catalog\", DEFAULT_CATALOG, \"Catalog\")\n",
        "    dbutils.widgets.text(\"schema_ref\", DEFAULT_SCHEMA_REF, \"Schema (ref)\")\n",
        "    dbutils.widgets.text(\"schema_bronze\", DEFAULT_SCHEMA_BRONZE, \"Schema (bronze)\")\n",
        "    dbutils.widgets.text(\"schema_silver\", DEFAULT_SCHEMA_SILVER, \"Schema (silver)\")\n",
        "    dbutils.widgets.text(\"schema_gold\", DEFAULT_SCHEMA_GOLD, \"Schema (gold)\")\n",
        "\n",
        "    dbutils.widgets.text(\"n_providers\", str(DEFAULT_N_PROVIDERS), \"N providers\")\n",
        "    dbutils.widgets.text(\"days_schedule\", str(DEFAULT_DAYS_SCHEDULE), \"Days schedule\")\n",
        "    dbutils.widgets.text(\"seed\", str(DEFAULT_SEED), \"Random seed\")\n",
        "\n",
        "    catalog = dbutils.widgets.get(\"catalog\") or DEFAULT_CATALOG\n",
        "    schema_ref = dbutils.widgets.get(\"schema_ref\") or DEFAULT_SCHEMA_REF\n",
        "    schema_bronze = dbutils.widgets.get(\"schema_bronze\") or DEFAULT_SCHEMA_BRONZE\n",
        "    schema_silver = dbutils.widgets.get(\"schema_silver\") or DEFAULT_SCHEMA_SILVER\n",
        "    schema_gold = dbutils.widgets.get(\"schema_gold\") or DEFAULT_SCHEMA_GOLD\n",
        "\n",
        "    N_PROVIDERS = int(dbutils.widgets.get(\"n_providers\") or DEFAULT_N_PROVIDERS)\n",
        "    DAYS_SCHEDULE = int(dbutils.widgets.get(\"days_schedule\") or DEFAULT_DAYS_SCHEDULE)\n",
        "    SEED = int(dbutils.widgets.get(\"seed\") or DEFAULT_SEED)\n",
        "except Exception:\n",
        "    catalog = DEFAULT_CATALOG\n",
        "    schema_ref = DEFAULT_SCHEMA_REF\n",
        "    schema_bronze = DEFAULT_SCHEMA_BRONZE\n",
        "    schema_silver = DEFAULT_SCHEMA_SILVER\n",
        "    schema_gold = DEFAULT_SCHEMA_GOLD\n",
        "\n",
        "    N_PROVIDERS = DEFAULT_N_PROVIDERS\n",
        "    DAYS_SCHEDULE = DEFAULT_DAYS_SCHEDULE\n",
        "    SEED = DEFAULT_SEED\n",
        "\n",
        "# Derived helpers\n",
        "fq = lambda sch, tbl: f\"{catalog}.{sch}.{tbl}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906b76f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unity Catalog bootstrap (you may need permissions to create catalogs/schemas)\n",
        "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog}\")\n",
        "spark.sql(f\"USE CATALOG {catalog}\")\n",
        "for sch in [schema_ref, schema_bronze, schema_silver, schema_gold]:\n",
        "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{sch}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47cdf633",
      "metadata": {},
      "source": [
        "## Create reference tables\n",
        "Tables created: `ref.facility`, `ref.department`, `ref.procedure`, `ref.credential_type`, `ref.payer`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36318ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "# ref.facility\n",
        "facility_rows = [\n",
        "    (\"FAC-001\", \"Manhattan General\", \"NYC\"),\n",
        "    (\"FAC-002\", \"Brooklyn Community\", \"NYC\"),\n",
        "    (\"FAC-003\", \"Queens Regional\", \"NYC\"),\n",
        "    (\"FAC-004\", \"Bronx Medical Center\", \"NYC\"),\n",
        "]\n",
        "facility_schema = StructType([\n",
        "    StructField(\"facility_id\", StringType(), False),\n",
        "    StructField(\"facility_name\", StringType(), False),\n",
        "    StructField(\"region\", StringType(), False),\n",
        "])\n",
        "facility_df = spark.createDataFrame(facility_rows, facility_schema)\n",
        "\n",
        "# ref.department\n",
        "department_rows = [\n",
        "    (\"D-001\", \"FAC-001\", \"Emergency\"),\n",
        "    (\"D-002\", \"FAC-001\", \"Surgery\"),\n",
        "    (\"D-003\", \"FAC-002\", \"Emergency\"),\n",
        "    (\"D-004\", \"FAC-002\", \"Anesthesiology\"),\n",
        "    (\"D-005\", \"FAC-003\", \"ICU\"),\n",
        "    (\"D-006\", \"FAC-004\", \"Cardiology\"),\n",
        "]\n",
        "department_schema = StructType([\n",
        "    StructField(\"dept_id\", StringType(), False),\n",
        "    StructField(\"facility_id\", StringType(), False),\n",
        "    StructField(\"dept_name\", StringType(), False),\n",
        "])\n",
        "department_df = spark.createDataFrame(department_rows, department_schema)\n",
        "\n",
        "# ref.procedure\n",
        "procedure_rows = [\n",
        "    (\"PROC-ER-INT\",   \"ER Initial Triage\",        \"D-001\", False, True),\n",
        "    (\"PROC-ER-SEDS\",  \"Moderate Sedation\",        \"D-001\", True,  True),\n",
        "    (\"PROC-SURG-APP\", \"Appendectomy\",             \"D-002\", True,  False),\n",
        "    (\"PROC-ANES-GEN\", \"General Anesthesia\",        \"D-004\", True,  True),\n",
        "    (\"PROC-ICU-VNT\",  \"Ventilator Management\",     \"D-005\", True,  True),\n",
        "    (\"PROC-CARD-ECG\", \"ECG Interpretation\",        \"D-006\", False, False),\n",
        "]\n",
        "procedure_schema = StructType([\n",
        "    StructField(\"procedure_code\", StringType(), False),\n",
        "    StructField(\"procedure_name\", StringType(), False),\n",
        "    StructField(\"dept_id\", StringType(), False),\n",
        "    StructField(\"requires_privilege\", BooleanType(), False),\n",
        "    StructField(\"requires_acls\", BooleanType(), False),\n",
        "])\n",
        "procedure_df = spark.createDataFrame(procedure_rows, procedure_schema)\n",
        "\n",
        "# ref.credential_type\n",
        "credential_type_rows = [\n",
        "    (\"STATE_MED_LICENSE\", \"State medical license (required for practice)\", 365*2),\n",
        "    (\"ACLS\",              \"Advanced Cardiovascular Life Support\",         365*2),\n",
        "    (\"DEA\",               \"Controlled substance registration (DEA)\",      365*3),\n",
        "]\n",
        "credential_type_schema = StructType([\n",
        "    StructField(\"cred_type\", StringType(), False),\n",
        "    StructField(\"cred_desc\", StringType(), False),\n",
        "    StructField(\"renewal_cycle_days\", IntegerType(), False),\n",
        "])\n",
        "credential_type_df = spark.createDataFrame(credential_type_rows, credential_type_schema)\n",
        "\n",
        "# ref.payer\n",
        "payer_rows = [\n",
        "    (\"PAY-001\", \"Medicare\"),\n",
        "    (\"PAY-002\", \"Medicaid\"),\n",
        "    (\"PAY-003\", \"Aetna\"),\n",
        "    (\"PAY-004\", \"UnitedHealthcare\"),\n",
        "    (\"PAY-005\", \"Blue Cross Blue Shield\"),\n",
        "]\n",
        "payer_schema = StructType([\n",
        "    StructField(\"payer_id\", StringType(), False),\n",
        "    StructField(\"payer_name\", StringType(), False),\n",
        "])\n",
        "payer_df = spark.createDataFrame(payer_rows, payer_schema)\n",
        "\n",
        "# Write as Delta tables in Unity Catalog\n",
        "facility_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"facility\"))\n",
        "department_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"department\"))\n",
        "procedure_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"procedure\"))\n",
        "credential_type_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"credential_type\"))\n",
        "payer_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"payer\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99a227ee",
      "metadata": {},
      "source": [
        "## Validate\n",
        "Count each table and display at least one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690d3e36",
      "metadata": {},
      "outputs": [],
      "source": [
        "tables = [\"facility\", \"department\", \"procedure\", \"credential_type\", \"payer\"]\n",
        "for t in tables:\n",
        "    c = spark.read.table(fq(schema_ref, t)).count()\n",
        "    print(f\"{fq(schema_ref, t)}: {c:,}\")\n",
        "\n",
        "display(spark.read.table(fq(schema_ref, \"procedure\")).orderBy(\"procedure_code\"))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

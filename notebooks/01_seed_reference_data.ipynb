{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 â€” Seed reference data (Unity Catalog + Delta)\n",
        "\n",
        "Creates small reference tables under the `ref` schema used by subsequent notebooks.\n",
        ""
      ],
      "id": "def77ed7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip install faker==25.2.0\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e74887ec"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configuration (Databricks widgets)\n",
        "# These widgets make the demo portable across workspaces/accounts.\n",
        "# If you're running this outside a Databricks notebook, it will fall back to defaults.\n",
        "\n",
        "DEFAULT_CATALOG = \"rtpa_catalog\"\n",
        "DEFAULT_SCHEMA_REF = \"credentialing_ref\"\n",
        "DEFAULT_SCHEMA_BRONZE = \"credentialing_bronze\"\n",
        "DEFAULT_SCHEMA_SILVER = \"credentialing_silver\"\n",
        "DEFAULT_SCHEMA_GOLD = \"credentialing_gold\"\n",
        "\n",
        "DEFAULT_N_PROVIDERS = 200\n",
        "DEFAULT_DAYS_SCHEDULE = 14\n",
        "DEFAULT_SEED = 42\n",
        "\n",
        "try:\n",
        "    dbutils.widgets.text(\"catalog\", DEFAULT_CATALOG, \"Catalog\")\n",
        "    dbutils.widgets.text(\"schema_ref\", DEFAULT_SCHEMA_REF, \"Schema (ref)\")\n",
        "    dbutils.widgets.text(\"schema_bronze\", DEFAULT_SCHEMA_BRONZE, \"Schema (bronze)\")\n",
        "    dbutils.widgets.text(\"schema_silver\", DEFAULT_SCHEMA_SILVER, \"Schema (silver)\")\n",
        "    dbutils.widgets.text(\"schema_gold\", DEFAULT_SCHEMA_GOLD, \"Schema (gold)\")\n",
        "\n",
        "    dbutils.widgets.text(\"n_providers\", str(DEFAULT_N_PROVIDERS), \"N providers\")\n",
        "    dbutils.widgets.text(\"days_schedule\", str(DEFAULT_DAYS_SCHEDULE), \"Days schedule\")\n",
        "    dbutils.widgets.text(\"seed\", str(DEFAULT_SEED), \"Random seed\")\n",
        "\n",
        "    catalog = dbutils.widgets.get(\"catalog\") or DEFAULT_CATALOG\n",
        "    schema_ref = dbutils.widgets.get(\"schema_ref\") or DEFAULT_SCHEMA_REF\n",
        "    schema_bronze = dbutils.widgets.get(\"schema_bronze\") or DEFAULT_SCHEMA_BRONZE\n",
        "    schema_silver = dbutils.widgets.get(\"schema_silver\") or DEFAULT_SCHEMA_SILVER\n",
        "    schema_gold = dbutils.widgets.get(\"schema_gold\") or DEFAULT_SCHEMA_GOLD\n",
        "\n",
        "    N_PROVIDERS = int(dbutils.widgets.get(\"n_providers\") or DEFAULT_N_PROVIDERS)\n",
        "    DAYS_SCHEDULE = int(dbutils.widgets.get(\"days_schedule\") or DEFAULT_DAYS_SCHEDULE)\n",
        "    SEED = int(dbutils.widgets.get(\"seed\") or DEFAULT_SEED)\n",
        "except Exception:\n",
        "    catalog = DEFAULT_CATALOG\n",
        "    schema_ref = DEFAULT_SCHEMA_REF\n",
        "    schema_bronze = DEFAULT_SCHEMA_BRONZE\n",
        "    schema_silver = DEFAULT_SCHEMA_SILVER\n",
        "    schema_gold = DEFAULT_SCHEMA_GOLD\n",
        "\n",
        "    N_PROVIDERS = DEFAULT_N_PROVIDERS\n",
        "    DAYS_SCHEDULE = DEFAULT_DAYS_SCHEDULE\n",
        "    SEED = DEFAULT_SEED\n",
        "\n",
        "# Derived helpers\n",
        "fq = lambda sch, tbl: f\"{catalog}.{sch}.{tbl}\"\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "bf679320"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Unity Catalog bootstrap (you may need permissions to create catalogs/schemas)\n",
        "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog}\")\n",
        "spark.sql(f\"USE CATALOG {catalog}\")\n",
        "for sch in [schema_ref, schema_bronze, schema_silver, schema_gold]:\n",
        "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{sch}\")\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "906b76f8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create reference tables\n",
        "Tables created: `ref.facility`, `ref.department`, `ref.procedure`, `ref.credential_type`, `ref.payer`, `ref.unit`, `ref.unit_certification`.\n"
      ],
      "id": "47cdf633"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "# ref.facility\n",
        "facility_rows = [\n",
        "    (\"FAC-001\", \"Manhattan General\", \"NYC\"),\n",
        "    (\"FAC-002\", \"Brooklyn Community\", \"NYC\"),\n",
        "    (\"FAC-003\", \"Queens Regional\", \"NYC\"),\n",
        "    (\"FAC-004\", \"Bronx Medical Center\", \"NYC\"),\n",
        "]\n",
        "facility_schema = StructType([\n",
        "    StructField(\"facility_id\", StringType(), False),\n",
        "    StructField(\"facility_name\", StringType(), False),\n",
        "    StructField(\"region\", StringType(), False),\n",
        "])\n",
        "facility_df = spark.createDataFrame(facility_rows, facility_schema)\n",
        "\n",
        "# ref.department\n",
        "department_rows = [\n",
        "    (\"D-001\", \"FAC-001\", \"Emergency\"),\n",
        "    (\"D-002\", \"FAC-001\", \"Surgery\"),\n",
        "    (\"D-003\", \"FAC-002\", \"Emergency\"),\n",
        "    (\"D-004\", \"FAC-002\", \"Anesthesiology\"),\n",
        "    (\"D-005\", \"FAC-003\", \"ICU\"),\n",
        "    (\"D-006\", \"FAC-004\", \"Cardiology\"),\n",
        "]\n",
        "department_schema = StructType([\n",
        "    StructField(\"dept_id\", StringType(), False),\n",
        "    StructField(\"facility_id\", StringType(), False),\n",
        "    StructField(\"dept_name\", StringType(), False),\n",
        "])\n",
        "department_df = spark.createDataFrame(department_rows, department_schema)\n",
        "\n",
        "# ref.procedure\n",
        "procedure_rows = [\n",
        "    (\"PROC-ER-INT\",   \"ER Initial Triage\",        \"D-001\", False, True),\n",
        "    (\"PROC-ER-SEDS\",  \"Moderate Sedation\",        \"D-001\", True,  True),\n",
        "    (\"PROC-SURG-APP\", \"Appendectomy\",             \"D-002\", True,  False),\n",
        "    (\"PROC-ANES-GEN\", \"General Anesthesia\",        \"D-004\", True,  True),\n",
        "    (\"PROC-ICU-VNT\",  \"Ventilator Management\",     \"D-005\", True,  True),\n",
        "    (\"PROC-CARD-ECG\", \"ECG Interpretation\",        \"D-006\", False, False),\n",
        "]\n",
        "procedure_schema = StructType([\n",
        "    StructField(\"procedure_code\", StringType(), False),\n",
        "    StructField(\"procedure_name\", StringType(), False),\n",
        "    StructField(\"dept_id\", StringType(), False),\n",
        "    StructField(\"requires_privilege\", BooleanType(), False),\n",
        "    StructField(\"requires_acls\", BooleanType(), False),\n",
        "])\n",
        "procedure_df = spark.createDataFrame(procedure_rows, procedure_schema)\n",
        "\n",
        "# ref.credential_type\n",
        "credential_type_rows = [\n",
        "    (\"STATE_MED_LICENSE\", \"State medical license (required for practice)\", 365*2),\n",
        "    (\"ACLS\",              \"Advanced Cardiovascular Life Support\",         365*2),\n",
        "    (\"DEA\",               \"Controlled substance registration (DEA)\",      365*3),\n",
        "]\n",
        "credential_type_schema = StructType([\n",
        "    StructField(\"cred_type\", StringType(), False),\n",
        "    StructField(\"cred_desc\", StringType(), False),\n",
        "    StructField(\"renewal_cycle_days\", IntegerType(), False),\n",
        "])\n",
        "credential_type_df = spark.createDataFrame(credential_type_rows, credential_type_schema)\n",
        "\n",
        "# ref.payer\n",
        "payer_rows = [\n",
        "    (\"PAY-001\", \"Medicare\"),\n",
        "    (\"PAY-002\", \"Medicaid\"),\n",
        "    (\"PAY-003\", \"Aetna\"),\n",
        "    (\"PAY-004\", \"UnitedHealthcare\"),\n",
        "    (\"PAY-005\", \"Blue Cross Blue Shield\"),\n",
        "]\n",
        "payer_schema = StructType([\n",
        "    StructField(\"payer_id\", StringType(), False),\n",
        "    StructField(\"payer_name\", StringType(), False),\n",
        "])\n",
        "payer_df = spark.createDataFrame(payer_rows, payer_schema)\n",
        "\n",
        "# ref.unit (hospital units for nurse staffing)\n",
        "unit_rows = [\n",
        "    (\"UNIT-ICU-001\", \"FAC-001\", \"ICU Tower A\", \"ICU\", 20, 2.0),\n",
        "    (\"UNIT-ICU-002\", \"FAC-002\", \"ICU West\", \"ICU\", 16, 2.0),\n",
        "    (\"UNIT-MEDSURG-001\", \"FAC-001\", \"Med-Surg 3rd Floor\", \"MED_SURG\", 40, 5.0),\n",
        "    (\"UNIT-MEDSURG-002\", \"FAC-002\", \"Med-Surg East\", \"MED_SURG\", 32, 5.0),\n",
        "    (\"UNIT-TELE-001\", \"FAC-001\", \"Telemetry Unit\", \"TELEMETRY\", 24, 4.0),\n",
        "    (\"UNIT-ED-001\", \"FAC-001\", \"Emergency Department\", \"ED\", 30, 4.0),\n",
        "    (\"UNIT-ED-002\", \"FAC-002\", \"Emergency Room\", \"ED\", 24, 4.0),\n",
        "    (\"UNIT-STEPDOWN-001\", \"FAC-001\", \"Step-Down Unit\", \"STEP_DOWN\", 18, 3.0),\n",
        "    (\"UNIT-OR-001\", \"FAC-001\", \"Operating Rooms\", \"OR\", 12, 1.0),\n",
        "    (\"UNIT-NICU-001\", \"FAC-003\", \"Neonatal ICU\", \"NICU\", 24, 2.0),\n",
        "]\n",
        "unit_schema = StructType([\n",
        "    StructField(\"unit_id\", StringType(), False),\n",
        "    StructField(\"facility_id\", StringType(), False),\n",
        "    StructField(\"unit_name\", StringType(), False),\n",
        "    StructField(\"unit_type\", StringType(), False),  # ICU, STEP_DOWN, MED_SURG, TELEMETRY, ED, OR, NICU, etc.\n",
        "    StructField(\"bed_count\", IntegerType(), False),\n",
        "    StructField(\"target_ratio\", FloatType(), False),  # Target nurse-to-patient ratio (patients per nurse)\n",
        "])\n",
        "unit_df = spark.createDataFrame(unit_rows, unit_schema)\n",
        "\n",
        "# ref.unit_certification (required certifications by unit type)\n",
        "unit_cert_rows = [\n",
        "    (\"ICU\", \"ACLS\", True),\n",
        "    (\"ICU\", \"BLS\", True),\n",
        "    (\"ICU\", \"Critical Care Certification\", True),\n",
        "    (\"STEP_DOWN\", \"ACLS\", True),\n",
        "    (\"STEP_DOWN\", \"BLS\", True),\n",
        "    (\"MED_SURG\", \"BLS\", True),\n",
        "    (\"TELEMETRY\", \"ACLS\", True),\n",
        "    (\"TELEMETRY\", \"BLS\", True),\n",
        "    (\"ED\", \"ACLS\", True),\n",
        "    (\"ED\", \"BLS\", True),\n",
        "    (\"ED\", \"TNCC\", True),\n",
        "    (\"ED\", \"PALS\", True),\n",
        "    (\"OR\", \"BLS\", True),\n",
        "    (\"OR\", \"ACLS\", True),\n",
        "    (\"NICU\", \"BLS\", True),\n",
        "    (\"NICU\", \"NRP\", True),\n",
        "]\n",
        "unit_cert_schema = StructType([\n",
        "    StructField(\"unit_type\", StringType(), False),\n",
        "    StructField(\"cred_type\", StringType(), False),\n",
        "    StructField(\"is_required\", BooleanType(), False),\n",
        "])\n",
        "unit_cert_df = spark.createDataFrame(unit_cert_rows, unit_cert_schema)\n",
        "\n",
        "# Write as Delta tables in Unity Catalog\n",
        "facility_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"facility\"))\n",
        "department_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"department\"))\n",
        "procedure_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"procedure\"))\n",
        "credential_type_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"credential_type\"))\n",
        "payer_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"payer\"))\n",
        "unit_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"unit\"))\n",
        "unit_cert_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(fq(schema_ref, \"unit_certification\"))\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e36318ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate\n",
        "Count each table and display at least one.\n"
      ],
      "id": "99a227ee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tables = [\"facility\", \"department\", \"procedure\", \"credential_type\", \"payer\", \"unit\", \"unit_certification\"]\n",
        "for t in tables:\n",
        "    c = spark.read.table(fq(schema_ref, t)).count()\n",
        "    print(f\"{fq(schema_ref, t)}: {c:,}\")\n",
        "\n",
        "display(spark.read.table(fq(schema_ref, \"unit\")).orderBy(\"unit_id\"))\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "690d3e36"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}